#!/usr/bin/env python3
"""
Script pour cr√©er un vrai test avec les bonnes valeurs (CORRECTION FINALE)
"""

import sqlite3
import os
import json
from datetime import datetime

def create_real_test_final():
    # Chemin vers la base de donn√©es
    db_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'app.db')
    print(f"üöÄ Cr√©ation d'un vrai test (CORRECTION FINALE)")
    print(f"üìÅ Base de donn√©es: {db_path}")
    print("=" * 60)
    
    try:
        # Connexion √† la base
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # 1. Cr√©er un nouveau test
        test_title = f"Test R√©el Cr√©√© - {datetime.now().strftime('%H:%M:%S')}"
        print(f"üìù Cr√©ation du test: {test_title}")
        
        cursor.execute("""
            INSERT INTO adaptive_tests (
                title, subject, description, difficulty_min, difficulty_max,
                estimated_duration, adaptation_type, learning_objectives,
                is_active, created_at, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            test_title,
            "Test Manuel",
            "Test cr√©√© manuellement pour v√©rifier l'affichage",
            1, 5, 20, "difficulty", "V√©rifier le syst√®me",
            1, datetime.now(), datetime.now()
        ))
        
        test_id = cursor.lastrowid
        print(f"‚úÖ Test cr√©√© avec l'ID: {test_id}")
        
        # 2. Cr√©er des questions avec les BONNES valeurs pour cognitive_level
        questions_data = [
            {
                "question_text": "Quelle est la capitale de la France?",
                "question_type": "multiple_choice",
                "options": json.dumps(["Paris", "Londres", "Berlin", "Madrid"]),
                "correct_answer": "Paris",
                "explanation": "C'est la capitale de la France",
                "difficulty_level": 1,
                "topic": "G√©ographie",
                "cognitive_level": "remember"  # ‚úÖ Valeur valide
            },
            {
                "question_text": "Combien font 2 + 2?",
                "question_type": "multiple_choice",
                "options": json.dumps(["3", "4", "5", "6"]),
                "correct_answer": "4",
                "explanation": "Op√©ration math√©matique simple",
                "difficulty_level": 1,
                "topic": "Math√©matiques",
                "cognitive_level": "apply"  # ‚úÖ Valeur valide
            },
            {
                "question_text": "Quel est le symbole chimique de l'eau?",
                "question_type": "multiple_choice",
                "options": json.dumps(["H2O", "CO2", "O2", "N2"]),
                "correct_answer": "H2O",
                "explanation": "Formule chimique de l'eau",
                "difficulty_level": 2,
                "topic": "Chimie",
                "cognitive_level": "understand"  # ‚úÖ Valeur valide
            }
        ]
        
        print(f"\nüîç Cr√©ation de {len(questions_data)} questions (avec les bonnes valeurs):")
        for i, q_data in enumerate(questions_data, 1):
            cursor.execute("""
                INSERT INTO adaptive_questions (
                    test_id, question_text, question_type, options, correct_answer,
                    explanation, difficulty_level, topic, cognitive_level,
                    question_order, is_active
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                test_id,
                q_data["question_text"],
                q_data["question_type"],
                q_data["options"],
                q_data["correct_answer"],
                q_data["explanation"],
                q_data["difficulty_level"],
                q_data["topic"],
                q_data["cognitive_level"],  # ‚úÖ Maintenant avec les bonnes valeurs
                i,  # question_order
                1   # is_active
            ))
            print(f"  ‚úÖ Question {i}: {q_data['question_text'][:30]}...")
        
        # 3. Valider les changements
        conn.commit()
        print(f"\nüíæ Changements sauvegard√©s dans la base")
        
        # 4. V√©rifier que le test est bien cr√©√©
        print(f"\nüîç V√©rification du test cr√©√©:")
        cursor.execute("""
            SELECT t.id, t.title, t.is_active, COUNT(q.id) as question_count
            FROM adaptive_tests t
            LEFT JOIN adaptive_questions q ON t.id = q.test_id
            WHERE t.id = ?
            GROUP BY t.id
        """, (test_id,))
        
        test_info = cursor.fetchone()
        if test_info:
            status = "‚úÖ ACTIF" if test_info[2] else "‚ùå INACTIF"
            print(f"  ID {test_info[0]}: {test_info[1]} - {status} - {test_info[3]} questions")
        
        # 5. V√©rifier l'endpoint /tests/simple/ maintenant
        print(f"\nüß™ Test de l'endpoint /tests/simple/ apr√®s cr√©ation:")
        cursor.execute("""
            SELECT 
                t.id,
                t.title,
                COUNT(q.id) as question_count
            FROM adaptive_tests t
            LEFT JOIN adaptive_questions q ON t.id = q.test_id AND q.is_active = 1
            WHERE t.is_active = 1
            GROUP BY t.id
            ORDER BY t.id
        """)
        
        endpoint_results = cursor.fetchall()
        print(f"  R√©sultats de l'endpoint: {len(endpoint_results)} tests")
        for result in endpoint_results:
            print(f"    ID {result[0]}: {result[1]} - {result[2]} questions")
        
        conn.close()
        print(f"\n‚úÖ Test cr√©√© avec succ√®s!")
        print(f"üéØ Maintenant va sur le frontend et rafra√Æchis la page!")
        print(f"   Le test '{test_title}' devrait appara√Ætre!")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    create_real_test_final()


















